{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Assignment _3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMp6XIaQ/vP4kYl5X35bzq7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trkfz2/M2020/blob/master/NLP_Assignment__3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vqDabVpPlG2",
        "colab_type": "code",
        "outputId": "52fe11bd-ad80-4959-9c6b-e5ebed9c045d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgklimX9PmfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPxub89qPrUx",
        "colab_type": "code",
        "outputId": "cdbacd99-8ac1-4a24-e09c-f53315ecb78c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR213YdHYkrM",
        "colab_type": "text"
      },
      "source": [
        "# Preparing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xnEuLv5YJyh",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Load the dataset that was prepared in task 1\n",
        "\n",
        "The original dataset is too large and needs to be reduced. You can for instance:\n",
        " - filter out items that have too many or too little tokens\n",
        " - select items of a certain type: post, comments or titles\n",
        " - or sub sample items randomly\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SDbKN5G1lpz",
        "colab_type": "code",
        "outputId": "530ca20a-172a-48ee-81ce-4dbe0b34e98d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1XOqQHEZwN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RK1ZD3AyV65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data into DataFrame\n",
        "\n",
        "data = pd.read_csv('drive/My Drive/Manning Project/NLP/stackexchange_812k.tokenized.csv').sample(frac = 1, random_state = 0).reset_index(drop = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnrjIP4h5T7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert data.shape == (789649, 7), \"The dataset does not have the right dimensions\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ainzreA6--a",
        "colab_type": "code",
        "outputId": "77a76f75-87fe-4731-c48b-f849f172e1cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "list(data.columns)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['post_id',\n",
              " 'parent_id',\n",
              " 'comment_id',\n",
              " 'text',\n",
              " 'category',\n",
              " 'tokens',\n",
              " 'n_tokens']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9YrqxTV8ZIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.options.display.max_colwidth = 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu7xB2fw8No1",
        "colab_type": "code",
        "outputId": "70a97715-d4da-4405-b6bd-78174d1e3d88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# show some examples\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>post_id</th>\n",
              "      <th>parent_id</th>\n",
              "      <th>comment_id</th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>tokens</th>\n",
              "      <th>n_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>298828</td>\n",
              "      <td>NaN</td>\n",
              "      <td>567970.0</td>\n",
              "      <td>That's not an option atm. This data definitely provides some evidence for length of adherence, I just don't know how to use it.</td>\n",
              "      <td>comment</td>\n",
              "      <td>that ' s not an option atm . this data definitely provides some evidence for length of adherence , i just don ' t know how to use it .</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>142749</td>\n",
              "      <td>142741.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>already provided a link to the discussion containing the theoretical aspects. Here is a quick pratical example of how one would do it in R. Please also have a look at these documents which contain the theory as well as examples Simultaneous Inference in General Parametric Models and Additional multcomp Examples . We will use the mtcars dataset and build a linear regression model containing three variables cyl Number of cylinders , disp Displacement and hp Horsepower to predict the variable m...</td>\n",
              "      <td>post</td>\n",
              "      <td>already provided a link to the discussion containing the theoretical aspects . here is a quick pratical example of how one would do it in r . please also have a look at these documents which contain the theory as well as examples simultaneous inference in general parametric models and additional multcomp examples . we will use the mtcars dataset and build a linear regression model containing three variables cyl number of cylinders , disp displacement and hp horsepower to predict the variable...</td>\n",
              "      <td>332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>49674</td>\n",
              "      <td>NaN</td>\n",
              "      <td>96088.0</td>\n",
              "      <td>As for I would say this question is off-topic and unlikely to help future visitors interested in statistical science in its theoretical and applied aspects.</td>\n",
              "      <td>comment</td>\n",
              "      <td>as for i would say this question is off - topic and unlikely to help future visitors interested in statistical science in its theoretical and applied aspects .</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>264715</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I attended a conference on ML and Data Science and I have a general question that was not answered in the conference. If we have a continuous variable, let's say age. What is the best way to handle this variable. These are my thoughts, please let me know if they nonsense, but in general I think it is a very important and useful topic that has not been discussed in the detail that I need it How should you decide on the number of bins? Would it be best to choose an arbitrary number of bins and...</td>\n",
              "      <td>post</td>\n",
              "      <td>i attended a conference on ml and data science and i have a general question that was not answered in the conference . if we have a continuous variable , let ' s say age . what is the best way to handle this variable . these are my thoughts , please let me know if they nonsense , but in general i think it is a very important and useful topic that has not been discussed in the detail that i need it how should you decide on the number of bins ? would it be best to choose an arbitrary number of...</td>\n",
              "      <td>258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>45344</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88126.0</td>\n",
              "      <td>Oh well, I actually meant equivalence in terms of only observed variables -- essentially maxing or more commonly, marginalizing out latent variables and then establishing equivalence.</td>\n",
              "      <td>comment</td>\n",
              "      <td>oh well , i actually meant equivalence in terms of only observed variables -- essentially maxing or more commonly , marginalizing out latent variables and then establishing equivalence .</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   post_id  ...  n_tokens\n",
              "0   298828  ...        30\n",
              "1   142749  ...       332\n",
              "2    49674  ...        28\n",
              "3   264715  ...       258\n",
              "4    45344  ...        29\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNe54TqB2NQ0",
        "colab_type": "text"
      },
      "source": [
        "**Training set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5iqF5OnEyU8",
        "colab_type": "code",
        "outputId": "3cee70e5-7339-410c-fddf-e6e9afa8b136",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(data['category'].unique())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['comment', 'post', 'title']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZO28MLS6sfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainign set will consist of comments and posts\n",
        "\n",
        "training = data[data.category.isin([\"post\",\"comment\"]) ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrwyfGVT7Q-8",
        "colab_type": "code",
        "outputId": "90fdaa09-beca-48d1-d912-b5fff85f3dec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "training.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(705964, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtfXrHl4ypHE",
        "colab_type": "code",
        "outputId": "f101e7fd-94d8-4c38-8df5-62ae5c4a7286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "training.category.value_counts()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "comment    540587\n",
              "post       165377\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6H22fJvzyB-",
        "colab_type": "code",
        "outputId": "345fcbb6-3b32-49a2-d639-90004667ae36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(\"Number of tokens per post or comment\")\n",
        "\n",
        "print(\"Minimum: {}\".format(training['n_tokens'].min()))\n",
        "print(\"Maximum: {}\".format(training['n_tokens'].max()))\n",
        "\n",
        "print(\"Average: {:.2f}\".format(training['n_tokens'].mean()))\n",
        "print(\"Median: {}\".format(training['n_tokens'].median()))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of tokens per post or comment\n",
            "Minimum: 5\n",
            "Maximum: 4903\n",
            "Average: 67.59\n",
            "Median: 42.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r3CfN9g0G96",
        "colab_type": "code",
        "outputId": "992d22b1-568d-4dd2-b7f3-c52194c4bd49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(\"Number of posts or comments with more than:\")\n",
        "print(\"100 tokens:{}\".format(training['n_tokens'].apply(lambda x: x > 100).sum()))\n",
        "\n",
        "print(\"500 tokens:{}\".format(training['n_tokens'].apply(lambda x: x > 500).sum()))\n",
        "\n",
        "print(\"1000 tokens:{}\".format(training['n_tokens'].apply(lambda x: x > 1000).sum()))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of posts or comments with more than:\n",
            "100 tokens:117479\n",
            "500 tokens:5517\n",
            "1000 tokens:674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFoYm5UP1ZEl",
        "colab_type": "code",
        "outputId": "3d3eab53-bf88-499c-a990-f7685a30c8ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(\"Percentage of posts or comments with more than:\")\n",
        "print(\"100 tokens:{:.2F}%\".format(\n",
        "    training['n_tokens'].apply(lambda x: x > 100).sum()/training.shape[0]*100))\n",
        "\n",
        "print(\"500 tokens:{:.2F}%\".format(\n",
        "    training['n_tokens'].apply(lambda x: x > 500).sum()/training.shape[0]*100))\n",
        "\n",
        "print(\"1000 tokens:{:.2F}%\".format(\n",
        "    training['n_tokens'].apply(lambda x: x > 1000).sum()/training.shape[0]*100))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of posts or comments with more than:\n",
            "100 tokens:16.64%\n",
            "500 tokens:0.78%\n",
            "1000 tokens:0.10%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTDtU2vy4T4F",
        "colab_type": "code",
        "outputId": "fdb80771-ccaf-4e04-9d0b-7b2b2b5d4e5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(\"Number of posts or comments with less than:\")\n",
        "print(\"20 tokens: {}\".format(training['n_tokens'].apply(lambda x: x <20).sum()))\n",
        "\n",
        "print(\"10 tokens: {}\".format(training['n_tokens'].apply(lambda x: x < 10).sum()))\n",
        "\n",
        "print(\"6 tokens: {}\".format(training['n_tokens'].apply(lambda x: x < 6).sum()))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of posts or comments with less than:\n",
            "20 tokens: 150907\n",
            "10 tokens: 41664\n",
            "6 tokens: 6232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1fN9_OY4Cc9",
        "colab_type": "code",
        "outputId": "038fa014-ac6d-4fe7-c06e-1c6f64d179d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(\"Percentage of posts or comments with less than:\")\n",
        "print(\"20 tokens:{:.2F}%\".format(training['n_tokens'].apply(lambda x: x < 20).sum()/training.shape[0]))\n",
        "\n",
        "print(\"10 tokens:{:.2F}%\".format(training['n_tokens'].apply(lambda x: x <10).sum()/training.shape[0]))\n",
        "\n",
        "print(\"6 tokens:{:.2F}%\".format(training['n_tokens'].apply(lambda x: x < 6).sum()/training.shape[0]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of posts or comments with less than:\n",
            "20 tokens:0.21%\n",
            "10 tokens:0.06%\n",
            "6 tokens:0.01%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbef82GWDNSB",
        "colab_type": "text"
      },
      "source": [
        "Remove some posts/comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7_5LLUP4lrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keep only posts and comments with the number of tokens between 20 and 100\n",
        "\n",
        "training_reduced = training[(training['n_tokens'] < 100) & (training['n_tokens'] >= 20)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCvDWHDm5uFa",
        "colab_type": "code",
        "outputId": "c51424d1-0008-49ed-e226-ba3e933e1738",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "training_reduced.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(435313, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCObga3T6L5-",
        "colab_type": "code",
        "outputId": "0f9fae21-2432-4e90-a6b3-a78603c6a4d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "training_reduced.shape[0]/training.shape[0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6166220940444556"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-IhUHUz7Kxv",
        "colab_type": "code",
        "outputId": "d88289cd-7f08-4e14-f35c-5371ce4c7d41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "training.category.value_counts()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "comment    540587\n",
              "post       165377\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVLaDB-77HyA",
        "colab_type": "code",
        "outputId": "e59c57a7-130b-4bb4-966f-d81f52d4790d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "training_reduced.category.value_counts()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "comment    368925\n",
              "post        66388\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-prXYzLT2UhF",
        "colab_type": "text"
      },
      "source": [
        "**Testing set**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWmrd2XVERh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for testing will use only titles\n",
        "\n",
        "testing = data[data.category == 'title']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlKHc8QmE48W",
        "colab_type": "code",
        "outputId": "e1982f5c-d72f-4351-951d-57520a5a8ce2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "testing.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(83685, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLucZYIsdDyj",
        "colab_type": "text"
      },
      "source": [
        "-----\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okS5fDekYZhf",
        "colab_type": "text"
      },
      "source": [
        "Build the vocabulary as the set of all unique tokens to construct the list of token indexes.\n",
        "\n",
        "Filtering on token frequency is one way to reduce the overall size of the vocabulary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZyillwDbQov",
        "colab_type": "code",
        "outputId": "a14c3dff-c607-43ad-9be5-88eeecf8e4b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!pip install --upgrade nltk"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nltk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
            "\r\u001b[K     |▎                               | 10kB 14.3MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 4.5MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 6.4MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 8.2MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61kB 6.2MB/s eta 0:00:01\r\u001b[K     |█▋                              | 71kB 7.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 81kB 7.9MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 8.7MB/s eta 0:00:01\r\u001b[K     |██▎                             | 102kB 6.7MB/s eta 0:00:01\r\u001b[K     |██▌                             | 112kB 6.7MB/s eta 0:00:01\r\u001b[K     |██▊                             | 122kB 6.7MB/s eta 0:00:01\r\u001b[K     |███                             | 133kB 6.7MB/s eta 0:00:01\r\u001b[K     |███▏                            | 143kB 6.7MB/s eta 0:00:01\r\u001b[K     |███▍                            | 153kB 6.7MB/s eta 0:00:01\r\u001b[K     |███▋                            | 163kB 6.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 174kB 6.7MB/s eta 0:00:01\r\u001b[K     |████                            | 184kB 6.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 194kB 6.7MB/s eta 0:00:01\r\u001b[K     |████▌                           | 204kB 6.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 215kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 225kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 235kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 245kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 256kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 266kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 276kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 286kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 296kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 307kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 317kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 327kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 337kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 348kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 358kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 368kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 378kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 389kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 399kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 409kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 419kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 430kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 440kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 450kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 460kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 471kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 481kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 491kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 501kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 512kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 522kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 532kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 542kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 552kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 563kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 573kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 583kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 593kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 604kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 614kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 624kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 634kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 645kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 655kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 665kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 675kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 686kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 696kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 706kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 716kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 727kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 737kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 747kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 757kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 768kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 778kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 788kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 798kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 808kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 819kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 829kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 839kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 849kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 860kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 870kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 880kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 890kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 901kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 911kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 921kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 931kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 942kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 952kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 962kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 972kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 983kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 993kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.0MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.0MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.0MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.0MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.0MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.2MB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.2MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.2MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.2MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.2MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.2MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.3MB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3MB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.3MB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.3MB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.3MB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.3MB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.3MB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.3MB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.3MB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.4MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.4MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.4MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.4MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.4MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.4MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.4MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.4MB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1449908 sha256=d6696f62b2db2e761d0c4892013c140cc7817ee2051de1a55402100feccb3aff\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
            "Successfully built nltk\n",
            "Installing collected packages: nltk\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJaqo6G_bblZ",
        "colab_type": "code",
        "outputId": "41a23088-7c51-49c3-b484-cfdb59a13238",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import nltk\n",
        "nltk.__version__"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.4.5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0JCTDMashzV",
        "colab_type": "code",
        "outputId": "362b7c3b-d5d7-4e82-b5c6-4acde18d9bc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "nltk.download()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> punkt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    Downloading package punkt to /root/nltk_data...\n",
            "      Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9Z8s9G_6YGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we only need tokens for training\n",
        "\n",
        "training_tokens  = training_reduced['tokens']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsGrOeB2d3Rt",
        "colab_type": "code",
        "outputId": "343ec0a1-3614-4911-ab4c-c6e34bce290c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(training_tokens)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "435313"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCjTtoBn-us_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk import tokenize\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p_8WiuBzWwBd",
        "colab": {}
      },
      "source": [
        "# split comments and posts into a list of sentences\n",
        "\n",
        "train_text = [list(tokenize.sent_tokenize(item)) for item in training_tokens]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKvgoD6mXTgw",
        "colab_type": "code",
        "outputId": "329483db-8e32-4fa1-9f41-ee742b44714c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#show some examples \n",
        "\n",
        "train_text[0:2]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[\"that ' s not an option atm .\",\n",
              "  \"this data definitely provides some evidence for length of adherence , i just don ' t know how to use it .\"],\n",
              " ['as for i would say this question is off - topic and unlikely to help future visitors interested in statistical science in its theoretical and applied aspects .']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGWifkdyliZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.lm.preprocessing import flatten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DgBr8M3Xa_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten rows into a single file\n",
        "\n",
        "flat_rows = list(flatten(train_text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qww0BkugXi0p",
        "colab_type": "code",
        "outputId": "d0ac33c2-3d88-4cc0-ef67-88498fd04f6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(flat_rows)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1304131"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnZx_DWdXlCX",
        "colab_type": "code",
        "outputId": "03680106-8251-4704-cf4e-0f8431a7bdee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# every item is a sentence\n",
        "\n",
        "flat_rows[100:110]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the comment by was directed at experienced statisticians who have been taught to use parameter to refer to hypothetical properties of a probability model and other words like characteristics or observations to refer to the things you measure and record .',\n",
              " 'so it is really dependent on mdp because there is another proof in this book dynamic programming and markov processes by howard for completely ergodic systems in the finite horizon .',\n",
              " \"and ... the answer in the mentioned link wasn ' t covering my problem !\",\n",
              " 'given a sample of data that contains only the score frequency distribution for scores below a certain threshold , is it possible to fit a complete normal distribution so to estimate what the will be the frequency for scores above the threshold .',\n",
              " 'good try .',\n",
              " \"you can fix the problem by using in doing so i believe you ' ll discover that for this result to be true , an additional assumption about the distribution is needed namely , that it has an expectation and the expectation is finite .\",\n",
              " 'do you mean journals that focus on methods for meta - analysis or journals that focus on publishing applied meta - analyses usually with focus on a particular discipline ?',\n",
              " 'are your categorical variables independent ?',\n",
              " 'as others pointed out , logistic regression assumes independent influence of the predictors .',\n",
              " \"if you don ' t think they are independent , then i suggest that you use a method that doesn ' t have this assumption .\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26Du12TDnC30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the length of sentences\n",
        "\n",
        "sent_length = [len(item) for item in flat_rows]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0glLq_9xnK3w",
        "colab_type": "code",
        "outputId": "90b7a80d-e6ce-41ef-e5d5-21e025120865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max(sent_length)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1042"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dba2JuxWnNmb",
        "colab_type": "code",
        "outputId": "f582f14c-116d-4944-8098-d4fb020f4d8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "min(sent_length)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ctfOHDOnTlX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "# count the number of sentences given the length\n",
        "\n",
        "sent_length_count = Counter(len(item) for item in flat_rows)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLsNrCxQnnJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sorted(sent_length_count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F27VCgfRT0o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "347cf6e5-b047-4ead-ceba-0f12bb6a6f7f"
      },
      "source": [
        "# show length counts\n",
        "i = 0\n",
        "for  k, v in sent_length_count.items():\n",
        "  print(k, \":\", v)\n",
        "  i +=1\n",
        "  if i>10:\n",
        "    break"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28 : 9177\n",
            "105 : 6752\n",
            "159 : 2731\n",
            "186 : 1550\n",
            "115 : 6048\n",
            "88 : 8209\n",
            "153 : 3102\n",
            "74 : 9262\n",
            "61 : 9975\n",
            "166 : 2387\n",
            "96 : 7424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H6G_f5wo63_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# how many sentences have less than 5 tokens?\n",
        "\n",
        "short_sent = [item for item in flat_rows if len(item) < 5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WZAOGnmpHqA",
        "colab_type": "code",
        "outputId": "375492be-c078-4e2d-bee6-f584eb1c4414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(short_sent)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58422"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhPoJd4OpKNL",
        "colab_type": "code",
        "outputId": "b5fd2ca6-3847-4184-972a-fdb615d7eeef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "# show some examples of short sentences\n",
        "\n",
        "short_sent[0:30]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['e .',\n",
              " 'cf .',\n",
              " 'c -.',\n",
              " 'g .',\n",
              " 'e .',\n",
              " 'g .',\n",
              " 'g .',\n",
              " 'e .',\n",
              " '.',\n",
              " 'see',\n",
              " 'g .',\n",
              " '?',\n",
              " '?',\n",
              " 'i .',\n",
              " '?',\n",
              " 'e .',\n",
              " ', .',\n",
              " 'g .',\n",
              " 'g .',\n",
              " 'here',\n",
              " '.',\n",
              " '.',\n",
              " '.',\n",
              " '.',\n",
              " '.',\n",
              " '.',\n",
              " '?',\n",
              " 'e .',\n",
              " 'e .',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgXvLokdn-y2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keep only sentences with number of tokens between 5 and 50\n",
        "\n",
        "flat_rows_reduced = [item for item in flat_rows if len(item)<=50 and len(item)>=5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw1ECNXCoKDw",
        "colab_type": "code",
        "outputId": "fbbd001e-bd1d-4766-db9b-0539474eaee2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(flat_rows), len(flat_rows_reduced)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1304131, 383313)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0I5VsoFMXSj",
        "colab_type": "text"
      },
      "source": [
        "-----\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QodprHkeJls9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_to_drive(x, file_name, folder):\n",
        "  import pickle, os\n",
        "  save_path = os.path.join('drive/My Drive/', folder, file_name + '.pickle')\n",
        "  print(save_path)\n",
        "  \n",
        "  with open(save_path, 'wb') as handle:\n",
        "    pickle.dump(x, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld6wTxy0KdXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_from_drive(file_name, folder):\n",
        "  import pickle, os\n",
        "  load_path = os.path.join('drive/My Drive/', folder, file_name + '.pickle')\n",
        "  print(load_path)\n",
        "  \n",
        "  with open(load_path, 'rb') as handle:\n",
        "    return pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2FmRyRbQsrk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3RKAuGRYdvq",
        "colab_type": "text"
      },
      "source": [
        "Set a fixed sequence length and build sequences of token indexes from the corpus. (see for instance keras pad_sequences)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJoH-qkAYguv",
        "colab_type": "text"
      },
      "source": [
        "Split the sequences into predictors and labels (keras.utils.to_categorical)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL8FTcgtyyyu",
        "colab_type": "code",
        "outputId": "22c96fc6-df79-4f14-df5b-b6f2d783c9fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NhSlOOH3f2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# limit hte dictionary to 1000 most used words\n",
        "\n",
        "num_words = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQYi92tfy-Ry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words = num_words, oov_token = '<UNK>' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giEj_VXM3v_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.fit_on_texts(flat_rows_reduced)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru6Hpx0lFCtq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_counts = tokenizer.word_counts\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRxB8gSLFGQH",
        "colab_type": "code",
        "outputId": "fd976aaf-2c28-47c9-c4ff-52f25536fa55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# show some word counts\n",
        "\n",
        "i = 0\n",
        "for  k, v in word_counts.items():\n",
        "  print(k, \":\", v)\n",
        "  i +=1\n",
        "  if i>10:\n",
        "    break"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "that : 30476\n",
            "' : 41975\n",
            "s : 15046\n",
            "not : 19807\n",
            "an : 7163\n",
            "option : 346\n",
            "atm : 6\n",
            "i : 78517\n",
            "gave : 318\n",
            "you : 63161\n",
            "link : 1841\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uGwfzvFPKRdB",
        "colab": {}
      },
      "source": [
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6HiF5yeT1Z-",
        "colab_type": "code",
        "outputId": "c5a4534c-fe7f-461d-8636-8b695e02c218",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# show some mappings\n",
        "\n",
        "i = 0\n",
        "for  k, v in word_index.items():\n",
        "  print(k, \":\", v)\n",
        "  i +=1\n",
        "  if i>10:\n",
        "    break\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<UNK> : 1\n",
            "the : 2\n",
            "i : 3\n",
            "you : 4\n",
            "is : 5\n",
            "a : 6\n",
            "' : 7\n",
            "to : 8\n",
            "for : 9\n",
            "it : 10\n",
            "this : 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0WBveJnkAac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get a token by its index\n",
        "\n",
        "index2word = {idx: word for (word, idx) in word_index.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8PDIrbNkIiK",
        "colab_type": "code",
        "outputId": "a5db02a2-9f15-427a-c80f-e1f5e6478372",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "index2word[1000]"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'repeated'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48VGkKjQ9FK0",
        "colab_type": "code",
        "outputId": "86e63bca-2e5a-4ccc-f82f-9845ced87e2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Unique tokens: {}'.format(len(word_index)))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens: 30513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SV9vMKNfPPyk",
        "colab_type": "code",
        "outputId": "50ea18b7-cd5e-4552-e695-9e23a4fa9683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab_size = num_words + 1\n",
        "vocab_size"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaMdWwweDth9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create ngram sequences for training\n",
        "\n",
        "ngram_seq = []\n",
        "for i, sentence in enumerate(flat_rows_reduced):\n",
        "  token_list = tokenizer.texts_to_sequences([sentence])[0]\n",
        "  for j in range(1, len(token_list)):\n",
        "    n_gram_sequence = token_list[:j+1]\n",
        "    ngram_seq.append(n_gram_sequence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpLb8_jAEgMO",
        "colab_type": "code",
        "outputId": "a31bbbd8-c743-40c1-e71d-f45332527382",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(ngram_seq)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1762942"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkvNo2q-EjcK",
        "colab_type": "code",
        "outputId": "685ceca5-5172-4c03-d0c3-882cd6c052c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "ngram_seq[0:20]"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[12, 7],\n",
              " [12, 7, 25],\n",
              " [12, 7, 25, 18],\n",
              " [12, 7, 25, 18, 45],\n",
              " [12, 7, 25, 18, 45, 642],\n",
              " [12, 7, 25, 18, 45, 642, 1],\n",
              " [3, 689],\n",
              " [3, 689, 4],\n",
              " [3, 689, 4, 12],\n",
              " [3, 689, 4, 12, 168],\n",
              " [3, 689, 4, 12, 168, 35],\n",
              " [3, 689, 4, 12, 168, 35, 2],\n",
              " [3, 689, 4, 12, 168, 35, 2, 1],\n",
              " [3, 689, 4, 12, 168, 35, 2, 1, 900],\n",
              " [59, 4],\n",
              " [59, 4, 320],\n",
              " [124, 1],\n",
              " [124, 1, 5],\n",
              " [124, 1, 5, 18],\n",
              " [124, 1, 5, 18, 176]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGg_78Kbkwfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find the sentence with most words\n",
        "\n",
        "max_seq_len = max([len(seq) for seq in ngram_seq])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfG-C1xGmsP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "min_seq_len = min([len(seq) for seq in ngram_seq])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EG7X9QTi-L5",
        "colab_type": "code",
        "outputId": "3ed0141c-13c4-4bdd-9cfd-0bff85e747bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# print some output to verify the above\n",
        "\n",
        "print('Original string: ', flat_rows_reduced[0])\n",
        "print('Sequence of Word Ids: ', ngram_seq[5])\n",
        "print('Word Ids back to Words: ', ' '.join([index2word[idx] for idx in ngram_seq[5]]))\n",
        "print('Max Sequence Length: ', max_seq_len)\n",
        "print('Min Sequence Length: ', min_seq_len)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original string:  that ' s not an option atm .\n",
            "Sequence of Word Ids:  [12, 7, 25, 18, 45, 642, 1]\n",
            "Word Ids back to Words:  that ' s not an option <UNK>\n",
            "Max Sequence Length:  22\n",
            "Min Sequence Length:  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC1hO3uzlJjW",
        "colab_type": "text"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQGruiRgytq6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_len = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOZIVg2--tPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ADZBBcHT56E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pad sequences to be of equal length\n",
        "\n",
        "ngram_seq_pad = pad_sequences(ngram_seq, maxlen = (seq_len + 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCLCfAnYUfWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg1cwWoiUkCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZaW5pWAUdC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shuffle \n",
        "\n",
        "np.random.shuffle(ngram_seq_pad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJH_LhTElunR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index2word[0] = '<0>'\n",
        "word_index['<0>'] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyc_co7IIZSL",
        "colab_type": "code",
        "outputId": "9deabeda-1bfe-4bf6-880b-35c5de120513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ngram_seq_pad.shape"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1762942, 21)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ6zC-7PEPze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split to X, y\n",
        "\n",
        "X, y = ngram_seq_pad[:, :-1], ngram_seq_pad[:,  -1] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnwqbQuVIjdj",
        "colab_type": "code",
        "outputId": "fe8a9773-2e54-4991-9dde-90c394b2d196",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1762942, 20), (1762942,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5shgzQNfQx7r",
        "colab_type": "text"
      },
      "source": [
        "----\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkJOwB0SE9tZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8HWaHe8EOKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert labels to categorical\n",
        "\n",
        "y = to_categorical(y, num_classes = vocab_size) # vocab_size = num_words + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9YZ3K4LF7kJ",
        "colab_type": "code",
        "outputId": "50f993ab-e707-4ddf-9e70-add6bf30184f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1762942, 20), (1762942, 1001))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoUon0UgVe3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training set\n",
        "\n",
        "x_train = X[:1700000,:]\n",
        "y_train = y[:1700000,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYsmjFIdVkI8",
        "colab_type": "code",
        "outputId": "4240216c-4ba3-4c0a-bf8c-694b87244d38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1700000, 20), (1700000, 1001))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s30L57aVVnGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# validation set\n",
        "\n",
        "x_val = X[1700000:,:]\n",
        "y_val = y[1700000:,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8vHUTWQVsZZ",
        "colab_type": "code",
        "outputId": "64f0e357-ed98-45cb-fa26-ec928b797291",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_val.shape, y_val.shape"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((62942, 20), (62942, 1001))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XtbPaos5jQ_",
        "colab_type": "text"
      },
      "source": [
        "-----\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPFGnRocYnzJ",
        "colab_type": "text"
      },
      "source": [
        "# The model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEe7BmH9YPEr",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "The data is now ready to be used to fit a neural network.\n",
        "\n",
        "Define a simple Sequential model with an embedding layer, LSTM(s) and a Dense layer with softmax activation. Feel free to experiment with dropouts, different optimizers. You can use any type of neural net you want: keras, tensorflow, pytorch, …\n",
        "\n",
        "Specify the number of epochs, the batch size and other fitting parameters\n",
        "Fit the network\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8tldda7Ndb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wWEKHflhNpj",
        "colab_type": "code",
        "outputId": "d81269da-a284-406f-f6eb-50866141b705",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvlivaqnhP52",
        "colab_type": "code",
        "outputId": "d381ca1d-34ea-498e-ea48-7ba1a6a4f412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seq_len"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPvmFrmFOyw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(vocab_size, 64, input_length = seq_len))\n",
        "model.add(LSTM(32, return_sequences = False)) \n",
        "model.add(Dense(vocab_size, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22PPfY0ARHQY",
        "colab_type": "code",
        "outputId": "f4319175-0b7f-4734-a4fc-13c5c23e9a9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 20, 64)            64064     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 32)                12416     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1001)              33033     \n",
            "=================================================================\n",
            "Total params: 109,513\n",
            "Trainable params: 109,513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d549ILhwRNok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer  = 'adam', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t_D2707Rafp",
        "colab_type": "code",
        "outputId": "eb503b02-4333-4f70-a12a-bb1825bd2b71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "history = model.fit(X, y, batch_size = 32, epochs = 3, validation_data =(x_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1762942 samples, validate on 62942 samples\n",
            "Epoch 1/3\n",
            "1762942/1762942 [==============================] - 2341s 1ms/step - loss: 3.9664 - acc: 0.2524 - val_loss: 3.7166 - val_acc: 0.2733\n",
            "Epoch 2/3\n",
            "1762942/1762942 [==============================] - 2346s 1ms/step - loss: 3.6480 - acc: 0.2817 - val_loss: 3.6202 - val_acc: 0.2818\n",
            "Epoch 3/3\n",
            "1762942/1762942 [==============================] - 2359s 1ms/step - loss: 3.5851 - acc: 0.2882 - val_loss: 3.5799 - val_acc: 0.2875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRUVSHUIReN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ipNxxGGxZjw",
        "colab_type": "code",
        "outputId": "f31f3e88-698d-40ab-9526-83525c534f8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label = \"Training acc\")\n",
        "plt.plot(epochs, val_acc, 'b', label = \"Validation acc\")\n",
        "plt.title(\"Train and Val ACC\")\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label = \"Training loss\")\n",
        "plt.plot(epochs, val_loss, 'b', label = \"Validation loss\")\n",
        "plt.title(\"Train and Val LOSS\")\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deZwU1b338c8PHBlW2QZFRjYVUbYZ\nGHBBFDVGXFFRI/FGiTeiPl41mkejcQEx5CY3PK/4mMckFxMVvSRInEgUt6BCEInLgIiCuICg4AKC\nbIII4+/549QwPc30TA803TPF9/161Wuqq05V/7opflV9TtU55u6IiEh8Ncp1ACIisncp0YuIxJwS\nvYhIzCnRi4jEnBK9iEjMKdGLiMScEr3UW2b2jJldVg/iGGtm/7MX9jvKzOZker8iyZToJaPMbHPC\n9K2ZbU14fUld9uXup7v7pL0V654ys05mtsPMDq1m3eNmNmEP9t3VzNzM9kuxfpSZvWVmW8zsMzP7\nvZm1Tljf2sweiNZtMrP3zOyWhPXDzWyBmW00sy/M7EUz67a78Ur9pkQvGeXuLSom4CPg7IRlkyvK\npUpgDYm7rwJeAH6QuNzM2gJnAHvlJGVmPwF+BdwEHAAcA3QBZpjZ/lGx3wAtgCOjMucAH0TbHwY8\nDPwkWtcNuA8o3xvxSu4p0UtWmNlQM1tpZj81s8+AB82sjZlNN7M1ZvZlNF+YsM0sM/tRND/KzOaY\n2YSo7IdmdnoN73eLmS2NrmYXm9l5Cetq3JeZdTOzf0bbzgDa1/DRJpGU6IGLgcXu/lZNcewOM2sF\n3AVc6+7Puvt2d18OXAR0Bf4tKjoQ+LO7f+nu37r7End/LFpXBHzo7i94sMndS939oz2JTeovJXrJ\npoOAtoSrz9GE4+/B6HVnYCvw/2rY/mjgXULi/S/gT2ZmKcouBYYQrljvAv7HzDqmua8/A/OidXcD\nNbUTPA60N7PjE5b9gMqr+driqKvjgHzgb4kL3X0z8DRwarToFWC8mf3QzA5P2sd8oKeZ/cbMTjKz\nFnsQjzQASvSSTd8CY9x9m7tvdfe10ZXkFnffBIwHTqxh+xXufr+7lxMSaUfgwOoKuvtf3f2T6Gr2\nUeB9YFBt+zKzzoSr4TuiOGcDT6YKyN23An8FLgWIkuoAwskinTjqqj3whbvvqGbdp1T++rgWmAz8\nB7DYzD6o+NXi7suAoUAnYCrwhZk9pIQfX0r0kk1r3P3rihdm1szM/tvMVpjZRmA20NrMGqfY/rOK\nGXffEs1Wm5zM7NKosXG9ma0HelO1CibVvg4GvnT3rxLKrqjlc00CLjSzfMLV/HPuvjrNOOrqC8Iv\niOraODpG64lOpL9w9wFAO0JC/2vUfoC7v+LuF7l7AeEXxwnAbXsQl9RjSvSSTcldpf4EOAI42t1b\nEZINQKrqmLSYWRfgfsLVbDt3bw28neZ+PwXamFnzhGWda9lmDrAOGE6oI5+UgThS+RewDTg/cWF0\nNX46oXG4CnffCPwCaE5oeE1e/zqhKqj3HsQl9ZgSveRSS0K9/ProSnNMhvbbnHBSWQNgZj8kzSTm\n7iuAMuAuM9s/qns/u5ZtnHAXy6+A1lRW9ex2HAmamFl+xQRsItT1/9bMhplZnpl1JVyxrwQeid7r\nDjMbGH2GfOB6YD3wrpkdb2ZXmFmHqGxPwl05r9QxNmkglOgll+4BmhKqG14Bns3ETt19MfB/CFe/\nnwN9gJfrsIvvExpr1xFOPg+nsc3DhCv/R919W4biANhMOBlWTCe7+38BPwMmABuBV4GPgVMq3ptw\ngnmQ8N1+QmikPTNqtF1PSOxvmdlmwvf+OKFRWmLINPCIiEi86YpeRCTmlOhFRGJOiV5EJOaU6EVE\nYq7edSzVvn1779q1a67DEBFpUObNm/dF9ADcLupdou/atStlZWW5DkNEpEExs5RPcKvqRkQk5pTo\nRURiToleRCTm6l0dvYhk3/bt21m5ciVff/117YUlp/Lz8yksLCQvLy/tbZToRYSVK1fSsmVLunbt\nSuqxXCTX3J21a9eycuVKunVLf4jf2FTdTJ4MXbtCo0bh7+TJtW0hIhW+/vpr2rVrpyRfz5kZ7dq1\nq/Mvr1hc0U+eDKNHw5Zo+IgVK8JrgEsuyV1cIg2JknzDsDv/TrG4or/ttsokX2HLlrBcRGRfF4tE\n/1GKsetTLReR+mXt2rUUFRVRVFTEQQcdRKdOnXa+/uabb2rctqysjOuuu67W9zjuuOMyEuusWbM4\n66yzMrKvbIlFou+cYqC3VMtFZM9kuk2sXbt2LFiwgAULFnDVVVdxww037Hy9//77s2NHdWOhByUl\nJdx77721vsfcuXP3LMgGLBaJfvx4aNas6rJmzcJyEcmsijaxFSvAvbJNLNM3QIwaNYqrrrqKo48+\nmptvvpnXXnuNY489luLiYo477jjeffddoOoV9tixY7n88ssZOnQo3bt3r3ICaNGixc7yQ4cO5YIL\nLqBnz55ccsklVAzA9PTTT9OzZ08GDBjAddddV+uV+7p16zj33HPp27cvxxxzDAsXLgTgn//8585f\nJMXFxWzatIlPP/2UE044gaKiInr37s1LL72U2S+sBrFojK1ocL3ttlBd07lzSPJqiBXJvJraxDL9\nf27lypXMnTuXxo0bs3HjRl566SX2228/nn/+eX72s59RWlq6yzZLlixh5syZbNq0iSOOOIKrr756\nl3vO33jjDRYtWsTBBx/M4MGDefnllykpKeHKK69k9uzZdOvWjZEjR9Ya35gxYyguLmbatGm8+OKL\nXHrppSxYsIAJEyZw3333MXjwYDZv3kx+fj4TJ07ktNNO47bbbqO8vJwtyV/iXhSLRA/hAFNiF9n7\nstkmduGFF9K4cWMANmzYwGWXXcb777+PmbF9+/ZqtznzzDNp0qQJTZo0oUOHDnz++ecUFhZWKTNo\n0KCdy4qKili+fDktWrSge/fuO+9PHzlyJBMnTqwxvjlz5uw82Zx88smsXbuWjRs3MnjwYG688UYu\nueQSzj//fAoLCxk4cCCXX34527dv59xzz6WoqGiPvpu6qLXqJhp9/jUze9PMFpnZXdWU6WJmL5jZ\nQjObZWaFCevKzWxBND2R6Q8gItmVzTax5s2b75y/4447OOmkk3j77bd58sknU95L3qRJk53zjRs3\nrrZ+P50ye+KWW27hj3/8I1u3bmXw4MEsWbKEE044gdmzZ9OpUydGjRrFww+nM+Z8ZqRTR7+NMPJ8\nP6AIGGZmxySVmQA87O59gXHAfyas2+ruRdF0TkaiFpGcyVWb2IYNG+jUqRMADz30UMb3f8QRR7Bs\n2TKWL18OwKOPPlrrNkOGDGFy1Dgxa9Ys2rdvT6tWrVi6dCl9+vThpz/9KQMHDmTJkiWsWLGCAw88\nkCuuuIIf/ehHzJ8/P+OfIZVaE70Hm6OXedHkScWOAl6M5mcCwzMWoYjUK5dcAhMnQpcuYBb+Tpy4\n96tOb775Zm699VaKi4szfgUO0LRpU373u98xbNgwBgwYQMuWLTnggANq3Gbs2LHMmzePvn37csst\ntzBp0iQA7rnnHnr37k3fvn3Jy8vj9NNPZ9asWfTr14/i4mIeffRRrr/++ox/hlSsorW5xkJmjYF5\nwGHAfe7+06T1fwZedff/a2bnA6VAe3dfa2Y7gAXADuCX7j6tpvcqKSlxDTwikl3vvPMORx55ZK7D\nyLnNmzfTokUL3J1rrrmGww8/nBtuuCHXYe2iun8vM5vn7iXVlU/r9kp3L3f3IqAQGGRmvZOK/G/g\nRDN7AzgRWAWUR+u6RG/+feAeMzs0ef9mNtrMysysbM2aNemEJCKScffffz9FRUX06tWLDRs2cOWV\nV+Y6pIxI64q+ygZmdwJb3H1CivUtgCXuXljNuoeA6e7+WKr964peJPt0Rd+wZPyK3swKzKx1NN8U\nOBVYklSmvZlV7OtW4IFoeRsza1JRBhgMLK7TJxIRkT2STtVNR2CmmS0EXgdmuPt0MxtnZhV30QwF\n3jWz94ADgYr29yOBMjN7k9BI+0t3V6IXEcmiWh+YcveFQHE1y+9MmH8M2KU6xt3nAn32MEYREdkD\nsejrRkREUlOiF5GcO+mkk3juueeqLLvnnnu4+uqrU24zdOhQKm7cOOOMM1i/fv0uZcaOHcuECdXe\nN7LTtGnTWLy4skb5zjvv5Pnnn69L+NWqT90ZK9GLSM6NHDmSKVOmVFk2ZcqUtDoWg9DrZOvWrXfr\nvZMT/bhx4/jOd76zW/uqr5ToRSTnLrjgAp566qmdg4wsX76cTz75hCFDhnD11VdTUlJCr169GDNm\nTLXbd+3alS+++AKA8ePH06NHD44//vidXRlDuEd+4MCB9OvXjxEjRrBlyxbmzp3LE088wU033URR\nURFLly5l1KhRPPZYaHJ84YUXKC4upk+fPlx++eVs27Zt5/uNGTOG/v3706dPH5YsWbJrUAly3Z1x\nbHqvFJHM+PGPYcGCzO6zqAjuuSf1+rZt2zJo0CCeeeYZhg8fzpQpU7joooswM8aPH0/btm0pLy/n\nlFNOYeHChfTt27fa/cybN48pU6awYMECduzYQf/+/RkwYAAA559/PldccQUAt99+O3/605+49tpr\nOeecczjrrLO44IILquzr66+/ZtSoUbzwwgv06NGDSy+9lN///vf8+Mc/BqB9+/bMnz+f3/3ud0yY\nMIE//vGPKT9frrsz1hW9iNQLidU3idU2U6dOpX///hQXF7No0aIq1SzJXnrpJc477zyaNWtGq1at\nOOecyn4U3377bYYMGUKfPn2YPHkyixYtqjGed999l27dutGjRw8ALrvsMmbPnr1z/fnnnw/AgAED\ndnaElsqcOXP4wQ9+AFTfnfG9997L+vXr2W+//Rg4cCAPPvggY8eO5a233qJly5Y17jsduqIXkSpq\nuvLem4YPH84NN9zA/Pnz2bJlCwMGDODDDz9kwoQJvP7667Rp04ZRo0al7J64NqNGjWLatGn069eP\nhx56iFmzZu1RvBVdHe9JN8e33HILZ555Jk8//TSDBw/mueee29md8VNPPcWoUaO48cYbufTSS/co\nVl3Ri0i90KJFC0466SQuv/zynVfzGzdupHnz5hxwwAF8/vnnPPPMMzXu44QTTmDatGls3bqVTZs2\n8eSTT+5ct2nTJjp27Mj27dt3di0M0LJlSzZt2rTLvo444giWL1/OBx98AMAjjzzCiSeeuFufLdfd\nGeuKXkTqjZEjR3LeeeftrMKp6Na3Z8+eHHLIIQwePLjG7fv378/3vvc9+vXrR4cOHRg4cODOdXff\nfTdHH300BQUFHH300TuT+8UXX8wVV1zBvffeu7MRFiA/P58HH3yQCy+8kB07djBw4ECuuuqq3fpc\nFWPZ9u3bl2bNmlXpznjmzJk0atSIXr16cfrppzNlyhR+/etfk5eXR4sWLTIyQEmdOzXb29SpmUj2\nqVOzhmWvdFMsIiINlxK9iEjMKdGLCAD1rRpXqrc7/05K9CJCfn4+a9euVbKv59ydtWvXkp+fX6ft\ndNeNiFBYWMjKlSvRUJ71X35+PoWFuwzgVyMlehEhLy+Pbt265ToM2UtUdSMiEnPpjBmbb2avmdmb\nZrbIzO6qpkwXM3vBzBaa2SwzK0xYd5mZvR9Nl2X6A4iISM3SuaLfBpzs7v2AImCYmR2TVGYC8LC7\n9wXGAf8JYGZtgTHA0cAgYIyZtclU8CIiUrtaE70Hm6OXedGU3DR/FPBiND8TGB7Nn0YYTHydu38J\nzACG7XHUIiKStrTq6M2ssZktAFYTEverSUXeBM6P5s8DWppZO6AT8HFCuZXRsuT9jzazMjMrU6u/\niEhmpZXo3b3c3YuAQmCQmfVOKvK/gRPN7A3gRGAVUJ5uEO4+0d1L3L2koKAg3c1ERCQNdbrrxt3X\nE6pmhiUt/8Tdz3f3YuC2hLKrgEMSihZGy0REJEvSueumwMxaR/NNgVOBJUll2ptZxb5uBR6I5p8D\nvmtmbaJG2O9Gy0REJEvSuaLvCMw0s4XA64Q6+ulmNs7MKsbpGgq8a2bvAQcC4wHcfR1wd7Td68C4\naJmIiGSJ+qMXEYkB9UcvIrIPU6IXEYk5JXoRkZhTohcRiTklehGRmFOiFxGJOSV6EZGYU6IXEYk5\nJXoRkZhTohcRiTklehGRmFOiFxGJOSV6EZGYU6IXEYk5JXoRkZhTohcRiTklehGRmEtnzNh8M3vN\nzN40s0Vmdlc1ZTqb2Uwze8PMFprZGdHyrma21cwWRNMf9saHEBGR1PZLo8w24GR332xmecAcM3vG\n3V9JKHM7MNXdf29mRwFPA12jdUvdvSijUYuISNpqTfQeBpXdHL3Mi6bkgWYdaBXNHwB8kqkARURk\nz6RVR29mjc1sAbAamOHuryYVGQv8m5mtJFzNX5uwrltUpfNPMxuSYv+jzazMzMrWrFlT908hIiIp\npZXo3b08qn4pBAaZWe+kIiOBh9y9EDgDeMTMGgGfAp3dvRi4EfizmbVK2hZ3n+juJe5eUlBQsCef\nR0REktTprht3Xw/MBIYlrfp3YGpU5l9APtDe3be5+9po+TxgKdBjT4MWEZH0pXPXTYGZtY7mmwKn\nAkuSin0EnBKVOZKQ6NdE2zaOlncHDgeWZS58ERGpTTp33XQEJkUJuxHh7prpZjYOKHP3J4CfAPeb\n2Q2EhtlR7u5mdgIwzsy2A98CV7n7ur3zUUREpDoWbqqpP0pKSrysrCzXYYiINChmNs/dS6pbpydj\nRURiToleRCTmlOhFRGJOiV5EJOaU6EVEYk6JXkQk5pToRURiToleRCTmlOhFRGJOiV5EJOaU6EVE\nYk6JXkQk5pToRURiToleRCTmlOhFRGJOiV5EJObSGUow38xeM7M3zWyRmd1VTZnOZjbTzN4ws4Vm\ndkbCulvN7AMze9fMTsv0BxARkZqlM5TgNuBkd99sZnnAHDN7xt1fSShzO2GIwd+b2VHA00DXaP5i\noBdwMPC8mfVw9/IMfw4REUmh1it6DzZHL/OiKXn8QQdaRfMHAJ9E88OBKe6+zd0/BD4ABu1x1CIi\nkra06ujNrLGZLQBWAzPc/dWkImOBfzOzlYSr+Wuj5Z2AjxPKrYyWJe9/tJmVmVnZmjVr6vgRRESk\nJmklencvd/cioBAYZGa9k4qMBB5y90LgDOARM0u7odfdJ7p7ibuXFBQUpLuZiIikoU533bj7emAm\nMCxp1b8DU6My/wLygfbAKuCQhHKF0TIREcmSdO66KTCz1tF8U+BUYElSsY+AU6IyRxIS/RrgCeBi\nM2tiZt2Aw4HXMhe+iIjUJp27bjoCk8ysMeHEMNXdp5vZOKDM3Z8AfgLcb2Y3EBpmR7m7A4vMbCqw\nGNgBXKM7bkREsstCPq4/SkpKvKysLNdhiIg0KGY2z91LqlunJ2NFRGJOiV5EJOaU6EVEYk6JXkQk\n5pToRURiToleRCTmlOhFRGJOiV5EJOaU6EVEYk6JXkQk5pToRURiToleRCTmlOhFRGJOiV5EJOaU\n6EVEYk6JXkQk5pToRURirtahBM0sH5gNNInKP+buY5LK/AY4KXrZDOjg7hXjzJYDb0XrPnL3czIU\nu4iIpCGdMWO3ASe7+2YzywPmmNkz7v5KRQF3v6Fi3syuBYoTtt/q7kUZi1hEROqk1qobDzZHL/Oi\nqaaBZkcCf8lAbCIikgFp1dGbWWMzWwCsBma4+6spynUBugEvJizON7MyM3vFzM5Nsd3oqEzZmjVr\n6vgRRESkJmklencvj6pfCoFBZtY7RdGLCXX45QnLukQjk38fuMfMDq1m/xPdvcTdSwoKCur4EURE\npCZ1uuvG3dcDM4FhKYpcTFK1jbuviv4uA2ZRtf5eRET2sloTvZkVmFnFHTRNgVOBJdWU6wm0Af6V\nsKyNmTWJ5tsDg4HFmQldRETSkc5dNx2BSWbWmHBimOru081sHFDm7k9E5S4Gprh7YkPtkcB/m9m3\n0ba/dHclehGRLLKqeTn3SkpKvKysLNdhiIg0KGY2L2oP3YWejBURiTklehGRmFOiFxGJOSV6EZGY\nU6IXEYk5JXoRkZhTohcRiTklehGRmFOiFxGJOSV6EZGYi02i37YNBg6EW2+FsjKoZz07iIjkTGwS\n/Zo10Lo1/PrXIeF36wY33ggvvwzffpvr6EREcic2ib6wEGbMgM8/hwcegN694b774Pjjw7prroEX\nX4QdO3IdqYhIdsW698qNG+Gpp6C0FJ5+GrZuhXbtYPhwGDECvvMd2H//jLyViEhO1dR7ZawTfaIt\nW+DZZ0PSf/JJ2LQJWrWCs88OSX/YMGjaNONvKyKSFUr0SbZtg+efD0n/73+HdeugWTM444yQ9M88\nE1q23KshiIhk1B71R29m+Wb2mpm9aWaLzOyuasr8xswWRNN7ZrY+Yd1lZvZ+NF22Zx8lM5o0Ccn8\ngQfgs89C3f6ll8JLL8HIkVBQAOecA5MmwZdf5jpaEZE9U+sVvZkZ0NzdN5tZHjAHuN7dX0lR/lqg\n2N0vN7O2QBlQAjgwDxjg7inTZy5HmCovh7lzw5X+3/4GH38M++0HJ58crvTPPRc6dMhJaCIiNdqj\nK3oPNkcv86KpprPDSOAv0fxpwAx3Xxcl9xnAsLQjz7LGjWHIELjnHlixAl57DX7yE1i2DK68Ejp2\nhKFD4be/hZUrcx2tiEh60rq90swam9kCYDUhcb+aolwXoBvwYrSoE/BxQpGV0bLk7UabWZmZla1Z\ns6Yu8e81ZuF+/F/+Et57D958E26/Hb74Aq67Dg45BI45Jty3v2xZrqMVEUktrUTv7uXuXgQUAoPM\nrHeKohcDj7l7eV2CcPeJ7l7i7iUFBQV12TQrzKBvX7jrLnj7bViyBMaPh+3b4eab4dBDobgYfv5z\neOedXEcrIlJVnR6Ycvf1wExSV79cTGW1DcAq4JCE14XRsgbtiCPgZz+DefPC1fyECeHWzDvugKOO\nCtMdd8CCBeqKQURyL527bgrMrHU03xQ4FVhSTbmeQBvgXwmLnwO+a2ZtzKwN8N1oWWx06xbq8efO\nDfX2v/0tHHgg/OIX4Sr/sMPCVf+rryrpi0hupHNF3xGYaWYLgdcJdfTTzWycmZ2TUO5iYIon3Mbj\n7uuAu6PtXgfGRctiqVMn+I//gJkzw22b998PPXqExt1jjoHOneH662H27HCHj4hINuyTD0xl2/r1\n4Wnc0tLwdO62beE2zfPOC7dtDh0KeXm5jlJEGjI9GVuPbN4c+t0pLQ398Hz1FbRpEx7QGjECTj0V\n8vNzHaWINDRK9PXU1q3wj3+EpP/EE7BhQ+h64cwzQ9I//XRo3jzXUYpIQ6BE3wB8803oRrm0FKZN\nC/frN20aOlsbMQLOOgsOOCDXUYpIfaVE38Ds2AFz5lR2xfDJJ6E75e98JyT94cNDd8siIhWU6Buw\nb78Nt2aWloZp+fLQVcPQoSHpn3ceHHRQrqMUkVxToo8Jd3jjjcqk/+674andwYND0j///HALp4js\ne5ToY8gdFi+uTPoLF4blJSUh6Y8YAYcfntsYRSR7lOj3AR98UJn0X389LOvTpzLp9+oVrv5FJJ6U\n6PcxH30Ejz8ekv6cOeHqv0ePyqTfv7+SvkjcKNHvwz77LNyuWVoaumYoL4euXUN9/ogRoWuGRnXq\n2k5E6iMlegFg7drwYFZpaRg+8Ztv4OCDK7tiGDIkjKglIg2PEr3sYsOG0AVDaSk880x4Srd9+3CP\n/ogRcMop4d59EWkYlOilRl99FTpbKy2F6dNh06bwFO7ZZ4ekf9pp4SldEam/lOglbV9/Dc8/H5L+\n3/8OX34Z+ts544yQ9M84I/THIyL1ixK97Jbt2+Gf/wxJ//HH4fPPoUmTcIU/YkS44m/TJtdRiggo\n0UsGlJeHUbQq+t/5+OPQcHvKKSHpn3su1MPhfkX2GUr0klHu4aGsige0li4Nt2gOGVLZFUOnTrmO\nUmTfUlOiT2fM2Hwze83M3jSzRWZ2V4pyF5nZ4qjMnxOWl5vZgmh6Yvc/htQXZjBoEPzqV/D++2EQ\n9NtugzVr4LrroLAQjj02DJr+4Ye5jlZE0nlUZhtwsrv3A4qAYWZ2TGIBMzscuBUY7O69gB8nrN7q\n7kXRlDjGrMSAGfTrB+PGwaJF8M478POfh+ESb7oJuncPT+KOHw9LdhlSvuGYPDk8aNaoUfg7eXKu\nIxJJX62J3oPN0cu8aEqu77kCuM/dv4y2WZ3RKKXB6NkzXN3Pnx+qdCZMCEMj3n47HHlk6HPnzjvh\nzTdDFVBDMHkyjB4NK1aEmFesCK+V7KWhSKuO3swaA/OAwwgJ/adJ66cB7wGDgcbAWHd/Nlq3A1gA\n7AB+6e7Tqtn/aGA0QOfOnQesWLFiTz6T1EOrVlX2vzN7duhn/9BDK/vfGTiw/va/07VrSO7JunQJ\n4wOI1AcZa4w1s9bA48C17v52wvLpwHbgIqAQmA30cff1ZtbJ3VeZWXfgReAUd1+a6j3UGBt/q1eH\ne/RLS+GFF8KIWoccUtn/znHHhcFV6otGjar/9WEWTlgi9cEeNcYmcvf1wExgWNKqlcAT7r7d3T8k\nXN0fHm2zKvq7DJgFFNcpeomdDh3giivC07irV8OkSVBcDH/4A5xwQrhj5+qrw4Nb27fnOtrUg7lo\nkBdpKNK566YgupLHzJoCpwLJzWrTgKFRmfZAD2CZmbUxsyYJywcDizMWvTR4bdrApZeGK/w1a2DK\nlJDsH3kETj01DJP4wx+Grhm2bctNjOPHQ7NmVZc1axaWizQE6VzRdwRmmtlC4HVghrtPN7NxZlZx\nF81zwFozW0y44r/J3dcCRwJlZvZmtPyX7q5EL9Vq2RK+9z2YOjUk/ccfD10uPP54eAq3oAC+//1Q\n5fPVV9mL65JLYOLEUCdvFv5OnBiWizQEemBK6r1vvoEXXwwJfto0+OKL0Mna6aeHOv2zzoJWrXId\npUhu6clYiY0dO+Cllyq7Yvj009Cd8qmnhqR/zjnQrl2uoxTJPiV6iaVvv4VXXqnsimHFinC3zkkn\nVfa/c9BBuY5SJDuU6CX23MNDWhVJ/733Qn368ceHpH/eebpLRuJNiV72Ke6hO4aKpP/WW2H5wIGV\nD2gddlhuYxTJNCV62ae9/ynYSB8AAArXSURBVH5l0q84tPr2rUz6Rx1Vf5/KFUmXEr1I5KOPQiNu\naSm8/HK4+j/iiMqkX1yspC8NkxK9SDU+/TTcrllaCrNmhcFVunatTPpHHx26PxBpCJToRWrxxRfw\nxBMh6c+YEbpeOPjgyv53jj8+jKglUl8p0YvUwYYNocuF0tLQH8/WreGp3OHDQ8I/9NDQz37Hjqrm\nkfpDiV5kN331FTzzTEj606fD5s2V65o2DQm/e/eQ/CtOAIceGqqAmjTJWdiyD6op0evHqEgNmjeH\nCy4I0/btof/5pUth2bLwt2L+hRdgy5bK7czCkIoVJ4DEk8Chh4bO3ESyRYleJE15eXD44WFK5g6f\nf77rCWDp0vBL4PPPq5Zv3br6E0D37uEEUZ/645eGT4leJAPMQncLBx0UBk5JtnlzGCg9+SQwf364\n3XPHjsqy++8fqn6qqxLq3n3XLpNFaqNEL5IFLVpAnz5hSlZeDh9/XH2V0L/+FRqHEx10UOpfAx06\nqIFYdqXGWJF6zB3Wrat6Akg8IaxaVXWYwxYtql79J54EunQJ1U8ST2qMFWmgzEK3y+3ahb56kn39\ndWUDceIJYMkSePrpqqNyNW4cOnarrkro0EPVp3+c1ZrozSyfMNh3k6j8Y+4+pppyFwFjAQfedPfv\nR8svA26Piv3c3SdlJnQRyc+Hnj3DlOzbb8PTv9VVCf3tb+EhsUTt2qWuEjr4YD0l3JDVWnVjZgY0\nd/fNZpYHzAGud/dXEsocDkwFTnb3L82sg7uvNrO2QBlQQjgBzAMGuPuXqd5PVTci2bFxY/V3CS1d\nGvoEKi+vLJufD926VX8S6NYtrJfc2qOqGw9ngorHRPKiKfnscAVwX0UCd/fV0fLTCGPMrosCmQEM\nA/5S1w8hIpnVqhUUFYUp2fbtIdlXdxKYObPqmL1m0KlT6iqhtm3VQJxradXRm1ljwtX4YYSE/mpS\nkR5RuZeBxsBYd38W6AR8nFBuZbRMROqxvLzKRJ3MPQzeXl2V0LPPhuqiRK1apa4SOuQQ9SGUDWl9\nxe5eDhSZWWvgcTPr7e5vJ+3ncGAoUAjMNrNqbiSrnpmNBkYDdNYwQCL1mlm4jbNDBzj22F3Xb9lS\n9ZmBipPAwoXw97+HXwsV9tuv5mcGWrTI2seKtTqdS919vZnNJFS/JCb6lcCr7r4d+NDM3iMk/lWE\n5F+hEJhVzX4nAhMh1NHXJSYRqV+aNYNevcKUrLw83BJaXZXQ66/Dl0mtdwcemLpK6MADVSWUrnQa\nYwuA7VGSbwr8A/iVu09PKDMMGOnul5lZe+ANoIjKBtj+UdH5hMbYdaneT42xIvuuL7/c9QRQ8frj\nj6s+M9CsWepnBrp2DU8Y70v29D76jsCkqJ6+ETDV3aeb2TigzN2fAJ4Dvmtmi4Fy4CZ3Xxu9+d3A\n69G+xtWU5EVk39amDZSUhCnZtm3hmYHkdoEPPoB//CN0J12hUaNQ/5/q10Dr1ln7SPWCnowVkQbP\nHT77rPoqoWXLYPXqquXbtKm5U7lsPzMweTLcdlu406lzZxg/Hi65pG770JOxIhJrZmEgmI4dw+Aw\nyTZtqkz+iSeBsrIw1kByp3Kpnhno3j2MQ5BJkyfD6NGV3VyvWBFeQ92TfSq6oheRfdqOHeFKOtXD\nY5s2VS1/8MGpq4Tat697A3HXriG5J+vSJVRVpUsjTImI7AZ3WLs2dZXQqlVVy7dsmbqBuHPn6juV\na9SoaiNzBbPQjUW6VHUjIrIbzMJVevv2cPTRu67furXymYHEk8DixfDUU7t2Ktely64ngIMO2vUh\nMwgnhkxRohcR2U1Nm8JRR4Up2bffhiv+6qqE/vrX0P10Ks2ahQbZTFGiFxHZCypu8TzkEDjxxF3X\nr19fmfhLS8MvgM2bw1X/7tx1UxMlehGRHGjdGvr3D9OFF+7d91IP0yIiMadELyISc0r0IiIxp0Qv\nIhJzSvQiIjGnRC8iEnNK9CIiMadELyISc/WuUzMzWwNU05db2toDX2QonExSXHWjuOpGcdVNHOPq\n4u4F1a2od4l+T5lZWaoe3HJJcdWN4qobxVU3+1pcqroREYk5JXoRkZiLY6KfmOsAUlBcdaO46kZx\n1c0+FVfs6uhFRKSqOF7Ri4hIAiV6EZGYazCJ3sweMLPVZvZ2ivVmZvea2QdmttDM+iesu8zM3o+m\ny7Ic1yVRPG+Z2Vwz65ewbnm0fIGZZXRE9DTiGmpmG6L3XmBmdyasG2Zm70bf5S1ZjuumhJjeNrNy\nM2sbrdub39chZjbTzBab2SIzu76aMlk9xtKMKVfHVzqxZf0YSzOurB9jZpZvZq+Z2ZtRXHdVU6aJ\nmT0afSevmlnXhHW3RsvfNbPT6hyAuzeICTgB6A+8nWL9GcAzgAHHAK9Gy9sCy6K/baL5NlmM67iK\n9wNOr4grer0caJ+j72soML2a5Y2BpUB3YH/gTeCobMWVVPZs4MUsfV8dgf7RfEvgveTPne1jLM2Y\ncnV8pRNb1o+xdOLKxTEWHTMtovk84FXgmKQy/wv4QzR/MfBoNH9U9B01AbpF313jurx/g7mid/fZ\nQA3D6TIceNiDV4DWZtYROA2Y4e7r3P1LYAYwLFtxufvc6H0BXgEKM/XeexJXDQYBH7j7Mnf/BphC\n+G5zEddI4C+Zeu+auPun7j4/mt8EvAN0SiqW1WMsnZhyeHyl832lsteOsd2IKyvHWHTMbI5e5kVT\n8p0ww4FJ0fxjwClmZtHyKe6+zd0/BD4gfIdpazCJPg2dgI8TXq+MlqVangv/TrgirODAP8xsnpmN\nzkE8x0Y/JZ8xs17RsnrxfZlZM0KyLE1YnJXvK/rJXEy46kqUs2OshpgS5eT4qiW2nB1jtX1n2T7G\nzKyxmS0AVhMuDFIeX+6+A9gAtCMD35cGB88SMzuJ8B/x+ITFx7v7KjPrAMwwsyXRFW82zCf0jbHZ\nzM4ApgGHZ+m903E28LK7J1797/Xvy8xaEP7j/9jdN2Zy37srnZhydXzVElvOjrE0/x2zeoy5ezlQ\nZGatgcfNrLe7V9tWlWlxuqJfBRyS8LowWpZqedaYWV/gj8Bwd19bsdzdV0V/VwOPU8efY3vC3TdW\n/JR096eBPDNrTz34viIXk/STem9/X2aWR0gOk939b9UUyfoxlkZMOTu+aostV8dYOt9ZJOvHWLTv\n9cBMdq3e2/m9mNl+wAHAWjLxfWW60WFvTkBXUjcunknVhrLXouVtgQ8JjWRtovm2WYyrM6FO7bik\n5c2Blgnzc4FhWYzrICofmBsEfBR9d/sRGhO7UdlQ1itbcUXrDyDU4zfP1vcVffaHgXtqKJPVYyzN\nmHJyfKUZW9aPsXTiysUxBhQAraP5psBLwFlJZa6hamPs1Gi+F1UbY5dRx8bYBlN1Y2Z/IbTitzez\nlcAYQoMG7v4H4GnCXREfAFuAH0br1pnZ3cDr0a7GedWfans7rjsJ9Wy/C+0q7PDQO92BhJ9vEA78\nP7v7s1mM6wLgajPbAWwFLvZwVO0ws/8AniPcHfGAuy/KYlwA5wH/cPevEjbdq98XMBj4AfBWVI8K\n8DNCIs3VMZZOTDk5vtKMLRfHWDpxQfaPsY7AJDNrTKhJmeru081sHFDm7k8AfwIeMbMPCCehi6OY\nF5nZVGAxsAO4xkM1UNrUBYKISMzFqY5eRESqoUQvIhJzSvQiIjGnRC8iEnNK9CIiMadELyISc0r0\nIiIx9/8Bj+mk0QDSZUgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcwYBodoYswt",
        "colab_type": "text"
      },
      "source": [
        "# Assessing the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEHUjIscYRCr",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Write a function that generates text\n",
        "\n",
        "generate some text and take note of\n",
        " - token repetitions\n",
        " - missing punctuations\n",
        " - other anomalies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnlQIbWrAeA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate words\n",
        "\n",
        "def generate_words(model, tokenizer, seq_len, seed_text, n_words, vocab_size):\n",
        "  \n",
        "  input_text = list(seed_text.split(\" \"))\n",
        "  \n",
        "  for i in range(n_words):\n",
        "    seq = tokenizer.texts_to_sequences([input_text])\n",
        "    \n",
        "    seq = pad_sequences(seq, maxlen = seq_len)\n",
        "    y_pred = model.predict_classes([seq], verbose  = 0)\n",
        "    word = index2word[y_pred[0]]\n",
        "\n",
        "    input_text.append(word)\n",
        "\t\n",
        "  return ' '.join(input_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlrjguQuO4Jk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate some sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZdeLZtvFJHG",
        "colab_type": "code",
        "outputId": "ed41a9dc-4dbc-4e61-9447-36265662eaa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seed_text = 'how'\n",
        "generate_words(model, tokenizer, seq_len, seed_text, 10, vocab_size) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'how can i do this <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MKE-zl4yhk6",
        "colab_type": "code",
        "outputId": "3d97a6d9-4a36-489e-b005-f2b33faba67a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seed_text = 'I'\n",
        "generate_words(model, tokenizer, seq_len, seed_text, 10, vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I ' m not sure what you mean by <UNK> <UNK>\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGwwtJHBy46i",
        "colab_type": "code",
        "outputId": "e49c9703-28a4-4afa-d6fd-8230cb2d47e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seed_text = 'what is the best'\n",
        "generate_words(model, tokenizer, seq_len, seed_text, 10, vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'what is the best way to do this <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPW2MqivzJKn",
        "colab_type": "code",
        "outputId": "0bf7dc1c-6544-4184-803d-12cabd5ddb19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seed_text = 'how many'\n",
        "generate_words(model, tokenizer, seq_len, seed_text, 10, vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'how many <UNK> are you <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dv3hSuIzMUP",
        "colab_type": "code",
        "outputId": "68f02b56-e9ca-4821-e164-b52a02c4610b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seed_text = 'another way to'\n",
        "generate_words(model, tokenizer, seq_len, seed_text, 10, vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'another way to do this <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzTFR74CzggQ",
        "colab_type": "text"
      },
      "source": [
        "----\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoma25NFY4K-",
        "colab_type": "text"
      },
      "source": [
        "Write a function that calculates perplexity of a sentence and apply it to a subset of sentences to evaluate the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTmOfDJVVT3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TO DO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcssNYN4Y54D",
        "colab_type": "text"
      },
      "source": [
        "Define a validation set, for instance 1000 titles\n",
        "Transform that validation set into sequences of tokens using the training vocabulary\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImVVdn2CY7fY",
        "colab_type": "text"
      },
      "source": [
        "Tune the neural net and the parameters of the pre processing phase to improve perplexity score of the model."
      ]
    }
  ]
}